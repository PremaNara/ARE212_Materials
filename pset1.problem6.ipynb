{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Set 1 (Problem 6)\n",
    "#### Description: Adaptation of Code in weighted_regression.ipynb\n",
    "#### Authors: Bobing, Cassandra, Max, Prema, Rajdev, and Yazen\n",
    "#### Date last modified: March 30, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "#### Notes:\n",
    "1. y = Xβ + u (simultaneous equations)\n",
    "- y is Nxk matrix\n",
    "- X is Nxl matrix\n",
    "- u is Nxk matrix\n",
    "- cov(u|X) = Ω (non-daiagonal matrix)\n",
    "- X = T \n",
    "2. In the example below, we take a general case with k =3, l =2, and Ω =3x3 non-diagonal matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 2 # Number of observables in T\n",
    "\n",
    "mu = [0]*l\n",
    "Sigma=[[1,0.5],\n",
    "       [0.5,2]]\n",
    "\n",
    "T = multivariate_normal(mu,Sigma) # T = Nx2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 # number of dependent variables in y\n",
    "\n",
    "mu = [0]*k\n",
    "Sigma=[[1,0.5,0.6],\n",
    "       [0.5,2,0.8],\n",
    "       [0.6,0.8,3]]\n",
    "\n",
    "u = multivariate_normal(mu,Sigma) # u = Nx3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = [[1/2,1,2],\n",
    "        [1,2,1/2]]    # beta = 2x3 matrix\n",
    "\n",
    "N=10000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "T = T.rvs(N)\n",
    "\n",
    "u = u.rvs(N) # Replace u with a sample\n",
    "\n",
    "X = T \n",
    "\n",
    "y = X@beta + u # Note use of @ operator for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49198901 0.9807464  1.99842893]\n",
      " [1.01058    2.00362346 0.47711673]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b = np.linalg.lstsq(T.T@X,T.T@y, rcond=None)[0] # lstsqs returns several results; we pick the first\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sanity check: b -> beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.32521888e-04 -5.77662143e-05]\n",
      " [-5.77662143e-05  1.14998758e-04]]\n"
     ]
    }
   ],
   "source": [
    "TXplus = np.linalg.pinv(T.T@X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Covariance matrix of b\n",
    "vb = e.var()*TXplus@T.T@T@TXplus.T  # u is known to be homoskedastic\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 \n",
    "#### Notes\n",
    "1. Since k =3, we have 3 equations to estimate as follows: \n",
    "- y1 = Xβ1 + u1\n",
    "- y2 = Xβ2 + u2\n",
    "- y3 = Xβ3 + u3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "l = 2 # Number of observables in T\n",
    "\n",
    "mu = [0]*l\n",
    "Sigma=[[1,0.5],\n",
    "       [0.5,2]]\n",
    "\n",
    "T = multivariate_normal(mu,Sigma) # T = Nx2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u1 = multivariate_normal(cov=1) # u1 = Nx1 matrix\n",
    "u2 = multivariate_normal(cov=2) # u2 = Nx1 matrix\n",
    "u3 = multivariate_normal(cov=3) # u3 = Nx1 matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = [1/2,1]\n",
    "beta2 = [1,2]\n",
    "beta3 = [2,1/2]\n",
    "\n",
    "N=10000 # Sample size\n",
    "\n",
    "T = T.rvs(N)\n",
    "\n",
    "u1 = u1.rvs(N) # Replace u1 with a sample\n",
    "u2 = u2.rvs(N) # Replace u2 with a sample\n",
    "u3 = u3.rvs(N) # Replace u3 with a sample\n",
    "\n",
    "X = T \n",
    "\n",
    "y1 = X@beta1 + u1 # Note use of @ operator for matrix multiplication\n",
    "y2 = X@beta2 + u2 \n",
    "y3 = X@beta3 + u3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b1 = np.linalg.solve(X.T@X,X.T@y1)\n",
    "b2 = np.linalg.solve(X.T@X,X.T@y2)\n",
    "b3 = np.linalg.solve(X.T@X,X.T@y3)\n",
    "\n",
    "e1 = y1 - X@b1\n",
    "e2 = y2 - X@b2\n",
    "e3 = y3 - X@b3\n",
    "\n",
    "vb1 = e1.var()*inv(X.T@X)\n",
    "vb2= e2.var()*inv(X.T@X)\n",
    "vb3 = e3.var()*inv(X.T@X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5025217  0.99610729] [0.98736455 1.99648165] [1.98856332 0.50218494]\n"
     ]
    }
   ],
   "source": [
    "print(b1, b2, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01073903 0.00765872] [0.01513624 0.01079467] [0.01835118 0.01308746]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(np.diag(vb1)), np.sqrt(np.diag(vb2)), np.sqrt(np.diag(vb3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing SUR with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From parts 2 and 3 above, the SUR estimates appear to be more efficient (i.e., lower variance) than the OLS estimates.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
